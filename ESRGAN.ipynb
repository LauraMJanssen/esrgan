{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SET UP"
      ],
      "metadata": {
        "id": "BmSZF30YBjwP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h7tNsFkRVEVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7613bb82-ef2b-4932-8595-017fb690ce2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwCjbXk6bwz5",
        "outputId": "c63e7992-1cff-448e-d1f9-ff37a7081ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'esrgan'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Total 44 (delta 0), reused 0 (delta 0), pack-reused 44\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n",
            "/content/esrgan\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu==2.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.6.0.66)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.64.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.47.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/LauraMJanssen/esrgan.git\n",
        "%cd esrgan/\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/esrgan\n",
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhd_9obBCA-1",
        "outputId": "ff515b6f-55a3-4a1a-a4ac-f6b3a02ed808"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For transfer learning:"
      ],
      "metadata": {
        "id": "2zK_yNzLmTD3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZi7Cvl9fPMq"
      },
      "source": [
        "Upload necessary files: checkpoint file & 2 weight files or esrgan_inference.zip (=pre-trained model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "naFvMby3bfbu"
      },
      "outputs": [],
      "source": [
        "! mkdir -p checkpoints/esrgan"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For esrgan_inference:"
      ],
      "metadata": {
        "id": "mWN0Nb_Emlho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZPZbmpLZx0D",
        "outputId": "3bd032c8-4050-47f1-c6d3-c8b977aceacd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/esrgan/pretrainedModel/esrgan_inference.zip\n",
            "   creating: /content/esrgan/pretrainedModel/esrgan_inference/\n",
            "  inflating: /content/esrgan/pretrainedModel/esrgan_inference/checkpoint  \n",
            "  inflating: /content/esrgan/pretrainedModel/esrgan_inference/ckpt-581.data-00000-of-00002  \n",
            "  inflating: /content/esrgan/pretrainedModel/esrgan_inference/ckpt-581.data-00001-of-00002  \n",
            "  inflating: /content/esrgan/pretrainedModel/esrgan_inference/ckpt-581.index  \n"
          ]
        }
      ],
      "source": [
        "! unzip \"/content/esrgan/pretrainedModel/esrgan_inference.zip\" -d \"/content/esrgan/pretrainedModel/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_X869PdjbW3U"
      },
      "outputs": [],
      "source": [
        "! mv /content/esrgan/pretrainedModel/esrgan_inference/* checkpoints/esrgan"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For other weights etc: adapt names! "
      ],
      "metadata": {
        "id": "zmh2r_1_mobd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jYoCNhF26sN"
      },
      "source": [
        "## Data Processing \\\\\n",
        "-> needs to be in '.tfrecod' format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD0njDfQWC0p",
        "outputId": "43c089ad-937a-4f9c-a564-95a911525c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/esrgan/data/DIV2K800_sub_bin.tfrecord': No such file or directory\n",
            "2022-08-27 11:26:33.991041: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-08-27 11:26:33.991231: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-08-27 11:26:33.991252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "I0827 11:26:34.801126 140589794490240 convert_train_tfrecord.py:62] Loading /content/gdrive/MyDrive/MA/IVUSImages_PNG_Train2\n",
            "I0827 11:26:34.801268 140589794490240 convert_train_tfrecord.py:65] Reading data list...\n",
            "I0827 11:27:03.110644 140589794490240 convert_train_tfrecord.py:77] Writing 5398 sample to tfrecord file...\n",
            "  0% 0/5398 [00:00<?, ?it/s]2022-08-27 11:27:31.987050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-08-27 11:27:32.047955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 11:27:32.048611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2022-08-27 11:27:32.064443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-08-27 11:27:32.287609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-08-27 11:27:32.324134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-08-27 11:27:32.343773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-08-27 11:27:32.555491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-08-27 11:27:32.598414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-08-27 11:27:32.994500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-27 11:27:32.994648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 11:27:32.995469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 11:27:32.996080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2022-08-27 11:27:32.996501: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-08-27 11:27:33.001335: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2022-08-27 11:27:33.001701: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2943100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-08-27 11:27:33.001738: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-08-27 11:27:33.242845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 11:27:33.243680: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29432c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-08-27 11:27:33.243713: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2022-08-27 11:27:33.243866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 11:27:33.244458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2022-08-27 11:27:33.244518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-08-27 11:27:33.244535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-08-27 11:27:33.244549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-08-27 11:27:33.244563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-08-27 11:27:33.244575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-08-27 11:27:33.244588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-08-27 11:27:33.244601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-08-27 11:27:33.244658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 11:27:33.245300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 11:27:33.245890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2022-08-27 11:27:33.245988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-08-27 11:27:33.247196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-08-27 11:27:33.247225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2022-08-27 11:27:33.247234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2022-08-27 11:27:33.247357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 11:27:33.247914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 11:27:33.248459: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-08-27 11:27:33.248501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            " 20% 1070/5398 [06:06<18:44,  3.85it/s]"
          ]
        }
      ],
      "source": [
        "! rm /content/esrgan/data/DIV2K800_sub_bin.tfrecord\n",
        "! python data/convert_train_tfrecord.py --hr_dataset_path='/content/gdrive/MyDrive/MA/IVUSImages_PNG_Train2' --lr_dataset_path='/content/gdrive/MyDrive/MA/IVUS_LowRes_Scale4_Train' --output_path=\"./data/DIV2K800_sub_bin.tfrecord\" --is_binary=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBKlHqRA3ZFG"
      },
      "outputs": [],
      "source": [
        "! rm /content/esrgan/data/DIV2K800_sub_bin_valid.tfrecord\n",
        "! python data/convert_train_tfrecord.py --hr_dataset_path='/content/gdrive/MyDrive/MA/IVUSImages_PNG_Valid2' --lr_dataset_path='/content/gdrive/MyDrive/MA/IVUS_LowRes_Scale4_Valid' --output_path=\"./data/DIV2K800_sub_bin_valid.tfrecord\" --is_binary=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-fvYoDI3Ahf"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs4DeEbXU-Cg"
      },
      "outputs": [],
      "source": [
        "! python train_esrgan.py --cfg_path=\"./configs/esrgan.yaml\" --gpu=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b45PCfKpdbCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998776b9-ab43-4ed7-ed4f-70e7f8eb9731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/esrgan-tf2/checkpoints/esrgan/ (stored 0%)\n",
            "  adding: content/esrgan-tf2/checkpoints/esrgan/ckpt-5.index (deflated 83%)\n",
            "  adding: content/esrgan-tf2/checkpoints/esrgan/ckpt-6.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/esrgan-tf2/checkpoints/esrgan/ckpt-6.index (deflated 83%)\n",
            "  adding: content/esrgan-tf2/checkpoints/esrgan/checkpoint (deflated 61%)\n",
            "  adding: content/esrgan-tf2/checkpoints/esrgan/ckpt-5.data-00000-of-00001 (deflated 8%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/ESRGAN_model.zip /content/esrgan-tf2/checkpoints/esrgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcF9q6wuXPxb"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/ESRGAN_model.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIdP0VZaYJOw"
      },
      "source": [
        "## TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) Define quality metric functions"
      ],
      "metadata": {
        "id": "078jO_JNDhGn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o9fcCGVH-YU"
      },
      "outputs": [],
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# define a function for peak signal-to-noise ratio (PSNR)\n",
        "def psnr(target, ref):\n",
        "         \n",
        "    # assume RGB image\n",
        "    target_data = target.astype(float)\n",
        "    ref_data = ref.astype(float)\n",
        "\n",
        "    diff = ref_data - target_data\n",
        "    diff = diff.flatten('C')\n",
        "\n",
        "    rmse = math.sqrt(np.mean(diff ** 2.))\n",
        "\n",
        "    return 20 * math.log10(255. / rmse)\n",
        "\n",
        "# define function for mean squared error (MSE)\n",
        "def mse(target, ref):\n",
        "    # the MSE between the two images is the sum of the squared difference between the two images\n",
        "    err = np.sum((target.astype('float') - ref.astype('float')) ** 2)\n",
        "    err /= float(target.shape[0] * target.shape[1])\n",
        "    \n",
        "    return err\n",
        "\n",
        "# define function that combines all three image quality metrics\n",
        "def compare_images(target, ref):\n",
        "    scores = []\n",
        "    scores.append(psnr(target, ref))\n",
        "    scores.append(mse(target, ref))\n",
        "    scores.append(ssim(target, ref, multichannel =True))\n",
        "    \n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) Execute model on specific image"
      ],
      "metadata": {
        "id": "GGulnXGnDku0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2_s_KAjt82c",
        "outputId": "69a3d8ce-1fa4-4479-8fc9-4479a44c8d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-26 23:55:25.246363: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-08-26 23:55:25.246449: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-08-26 23:55:25.246464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "I0826 23:55:26.170805 140266753300352 utils.py:30] Detect 1 Physical GPUs, 1 Logical GPUs.\n",
            "[*] load ckpt from ./checkpoints/esrgan/ckpt-1.\n",
            "[*] Processing on single image /content/gdrive/MyDrive/MA/NoisyIm_Large/Noisy_m0005_M0005.png\n",
            "[Noisy_m0005_M0005.png] PSNR/SSIM: Bic=29.68db/0.87, SR=11.56db/0.16\n",
            "[*] write the result image ./Bic_SR_HR_Noisy_m0005_M0005.png\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "!python test.py --cfg_path=\"./configs/esrgan.yaml\" --img_path=\"/content/gdrive/MyDrive/MA/IVUSImages_PNG_Valid2/001.png\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) Print results\n",
        "(make sure to adapt ref and degraded parts according to image read above)"
      ],
      "metadata": {
        "id": "zN4bzi79DnnZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-JoFXe0IBIS",
        "outputId": "556d48c8-d4c0-4f71-88a5-249a5898fb1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degraded Image: \n",
            "PSNR: 29.40398264707939\n",
            "MSE: 223.77076721191406\n",
            "SSIM: 0.8560081594432712\n",
            "\n",
            "Reconstructed Image: \n",
            "PSNR: 24.284026710372892\n",
            "MSE: 727.4429588317871\n",
            "SSIM: 0.7063703437527753\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "ref = cv2.imread('/content/gdrive/MyDrive/MA/IVUSImages_PNG_Valid2/001.png')\n",
        "degraded = cv2.imread('/content/gdrive/MyDrive/MA/IVUS_LowRes_Scale4_Valid/001.png')\n",
        "output = cv2.imread('/content/result.png')\n",
        "  \n",
        "# image quality calculations\n",
        "scores = []\n",
        "h, w, _ = degraded.shape\n",
        "degraded2 = cv2.resize(degraded, (4*w, 4*h))\n",
        "scores.append(compare_images(degraded2, ref))\n",
        "\n",
        "scores.append(compare_images(output, ref))\n",
        "\n",
        "  \n",
        "# print all scores for all images\n",
        "print('Degraded Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[0][0], scores[0][1], scores[0][2]))\n",
        "print('Reconstructed Image: \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[1][0], scores[1][1], scores[1][2]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ESRGAN",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}